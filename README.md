# Conversational AI With Tiered Emotional Intelligence  
*A Hybrid LLM + Sentiment Intelligence System*  
**Author: Saheb Ansari**

---

## ğŸ“˜ Introduction
This project delivers a next-generation conversational AI system that goes far beyond simple text replies. By combining a **fine-tuned RoBERTa sentiment classifier** with **Googleâ€™s Gemini 2.5 Flash LLM**, the system performs:

- Real-time empathetic conversation  
- Deep emotional diagnostics  
- Multi-layer behavioral reasoning  
- End-of-session intelligence reporting for business insights  

This hybrid design enables both **human-like responses** and **high-value analytical output**, ideal for customer support, mental health platforms, enterprise automation, and conversational analytics.

---

## â­ Why This Model Is Superior
### 1. Deeper Contextual Empathy
RoBERTa provides **pre-validated sentiment labels** and confidence scores, letting Gemini focus on generating strategic, empathetic responses.

### 2. Tiered Business Intelligence
- **Tier 1 â€“ Sentiment Classification**  
- **Tier 2 â€“ Emotion-aware Real-time Responses**  
- **Tier 3 â€“ Full-Conversation Diagnostic Report**  

The system outputs summaries, trend analysis, and actionable recommendations.

### 3. Cost-Optimized, Low-Latency Architecture
Gemini Flash ensures:
- High throughput  
- Fast real-time responses  
- Strong reasoning for summaries  

---

## ğŸ§  Technologies Used
- **RoBERTa-base (social media fine-tuned)**  
- **Google Gemini 2.5 Flash (Google GenAI SDK)**  
- **Structured System Prompting**  

---

## ğŸ”„ End-to-End Model Flow
### Step 1 â€” Tier 1 Analysis
User message â†’ RoBERTa outputs sentiment â†’ stored in history.

### Step 2 â€” Tier 2 Real-Time Response
Sentiment and message are included in Gemini prompt â†’ empathetic reply.

### Step 3 â€” Tier 3 Post-Conversation Analysis
Full annotated conversation is sent to Gemini â†’ narrative summary + trend map + actionable insights.

---

## ğŸ“¦ Inferred Dependencies
```
transformers
torch
google-genai
python-dotenv
fastapi
uvicorn
pydantic
numpy
```

---

## ğŸ› ï¸ Installation
```bash
pip install transformers torch google-genai python-dotenv fastapi uvicorn
```

---

## â–¶ï¸ Usage Example
```python
sentiment = roberta_model.predict(user_input)

prompt = "Sentiment detected: {} (Score: {})\nUser message: {}".format(
    sentiment.label, sentiment.score, user_input
)

response = gemini.generate(prompt)
```

---

## ğŸ§© System Architecture
User â†’ RoBERTa â†’ Gemini Flash â†’ Response  
â€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ€ƒâ†“  
â€ƒâ€ƒâ€ƒâ€ƒTier 3 Analytics  

---

## ğŸ§ª Features
- Hybrid LLM + ML pipeline  
- Emotion-aware conversational agent  
- Session-level business intelligence  
- Low latency, production-ready design  

---

## ğŸ› Troubleshooting
| Issue | Cause | Fix |
|-------|--------|------|
| Slow responses | No streaming | Enable Gemini streaming |
| Wrong sentiment | Insufficient tuning | Re-train RoBERTa |
| Poor summaries | Weak prompts | Strengthen Tier 3 instructions |

---

## ğŸ‘¤ Author
**Saheb Ansari**

---


